{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesla Stock SQL Analysis\n",
    "## Applied Data Science Capstone Project\n",
    "\n",
    "**Objetivo**: Realizar an√°lisis avanzado de datos de Tesla usando SQL\n",
    "\n",
    "**√Åreas de an√°lisis SQL**:\n",
    "- Consultas de rendimiento temporal\n",
    "- An√°lisis de patrones de trading\n",
    "- Indicadores t√©cnicos con SQL\n",
    "- An√°lisis de volatilidad\n",
    "- Consultas de correlaci√≥n y tendencias"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:29:56.569095Z",
     "start_time": "2025-08-13T14:29:56.554092Z"
    }
   },
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas exitosamente\")\n",
    "print(\"üìä Listo para an√°lisis SQL de datos de Tesla\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas exitosamente\n",
      "üìä Listo para an√°lisis SQL de datos de Tesla\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurar Base de Datos SQLite"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:29:56.538093300Z",
     "start_time": "2025-08-13T09:01:33.944346Z"
    }
   },
   "source": [
    "# Configurar conexi√≥n a base de datos SQLite\n",
    "def setup_database():\n",
    "    \"\"\"\n",
    "    Configurar base de datos SQLite y cargar datos de Tesla\n",
    "    \"\"\"\n",
    "    tesla_df = None\n",
    "    conn = None\n",
    "    \n",
    "    try:\n",
    "        # Intentar cargar datos desde archivo limpio\n",
    "        tesla_df = pd.read_csv('data/clean/tesla_final_dataset.csv', index_col=0, parse_dates=True)\n",
    "        print(f\"‚úÖ Datos cargados desde archivo: {tesla_df.shape}\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è Archivo de datos no encontrado. Creando datos de ejemplo...\")\n",
    "        try:\n",
    "            import yfinance as yf\n",
    "            tesla_df = yf.download('TSLA', start='2020-01-01', end='2024-01-01', progress=False)\n",
    "            \n",
    "            # Normalizar columnas si es necesario\n",
    "            if isinstance(tesla_df.columns, pd.MultiIndex):\n",
    "                tesla_df.columns = tesla_df.columns.get_level_values(0)\n",
    "            \n",
    "            tesla_df.columns = [str(col).title() for col in tesla_df.columns]\n",
    "            tesla_df['Daily_Return'] = tesla_df['Close'].pct_change()\n",
    "            tesla_df = tesla_df.dropna()\n",
    "            \n",
    "            print(f\"‚úÖ Datos descargados con yfinance: {tesla_df.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error con yfinance: {e}\")\n",
    "            print(\"üîß Creando datos sint√©ticos...\")\n",
    "            \n",
    "            # Crear datos sint√©ticos\n",
    "            dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "            np.random.seed(42)\n",
    "            n_days = len(dates)\n",
    "            \n",
    "            price_changes = np.random.normal(0.001, 0.03, n_days)\n",
    "            prices = 100 * np.exp(np.cumsum(price_changes))\n",
    "            \n",
    "            tesla_df = pd.DataFrame({\n",
    "                'Open': prices * np.random.uniform(0.98, 1.02, n_days),\n",
    "                'High': prices * np.random.uniform(1.00, 1.05, n_days),\n",
    "                'Low': prices * np.random.uniform(0.95, 1.00, n_days),\n",
    "                'Close': prices,\n",
    "                'Volume': np.random.randint(10000000, 100000000, n_days),\n",
    "                'Daily_Return': np.random.normal(0.001, 0.03, n_days)\n",
    "            }, index=dates)\n",
    "            \n",
    "            tesla_df = tesla_df.dropna()\n",
    "            print(f\"‚úÖ Datos sint√©ticos creados: {tesla_df.shape}\")\n",
    "    \n",
    "    if tesla_df is not None:\n",
    "        try:\n",
    "            # Crear conexi√≥n SQLite en memoria\n",
    "            conn = sqlite3.connect(':memory:')\n",
    "            \n",
    "            # Preparar DataFrame para SQL\n",
    "            tesla_sql = tesla_df.reset_index()\n",
    "            tesla_sql.columns = [col.replace(' ', '_') for col in tesla_sql.columns]\n",
    "            \n",
    "            # Asegurar que tenemos columnas b√°sicas\n",
    "            required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "            for col in required_columns:\n",
    "                if col not in tesla_sql.columns and col.lower() in [c.lower() for c in tesla_sql.columns]:\n",
    "                    # Encontrar la columna con nombre similar\n",
    "                    actual_col = [c for c in tesla_sql.columns if c.lower() == col.lower()][0]\n",
    "                    tesla_sql = tesla_sql.rename(columns={actual_col: col})\n",
    "            \n",
    "            # Agregar columnas calculadas si no existen\n",
    "            if 'Daily_Return' not in tesla_sql.columns:\n",
    "                tesla_sql['Daily_Return'] = tesla_sql['Close'].pct_change()\n",
    "            \n",
    "            # Agregar m√°s caracter√≠sticas para an√°lisis SQL\n",
    "            tesla_sql['Price_Range'] = tesla_sql['High'] - tesla_sql['Low']\n",
    "            tesla_sql['Price_Change'] = tesla_sql['Close'] - tesla_sql['Open']\n",
    "            tesla_sql['Year'] = pd.to_datetime(tesla_sql['Date']).dt.year\n",
    "            tesla_sql['Month'] = pd.to_datetime(tesla_sql['Date']).dt.month\n",
    "            tesla_sql['DayOfWeek'] = pd.to_datetime(tesla_sql['Date']).dt.dayofweek\n",
    "            tesla_sql['Quarter'] = pd.to_datetime(tesla_sql['Date']).dt.quarter\n",
    "            \n",
    "            # Cargar datos a SQLite\n",
    "            tesla_sql.to_sql('tesla_stock', conn, index=False, if_exists='replace')\n",
    "            \n",
    "            print(f\"‚úÖ Base de datos SQLite configurada exitosamente\")\n",
    "            print(f\"üìä Tabla 'tesla_stock' creada con {len(tesla_sql)} filas\")\n",
    "            print(f\"üìÖ Per√≠odo: {tesla_sql['Date'].min()} a {tesla_sql['Date'].max()}\")\n",
    "            \n",
    "            # Mostrar esquema de la tabla\n",
    "            schema_query = \"PRAGMA table_info(tesla_stock)\"\n",
    "            schema = pd.read_sql_query(schema_query, conn)\n",
    "            print(f\"\\nüìã ESQUEMA DE LA TABLA:\")\n",
    "            for _, row in schema.iterrows():\n",
    "                print(f\"  ‚Ä¢ {row['name']}: {row['type']}\")\n",
    "            \n",
    "            return conn, tesla_sql\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error configurando base de datos: {e}\")\n",
    "            if conn:\n",
    "                conn.close()\n",
    "            return None, None\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Ejecutar configuraci√≥n\n",
    "conn, tesla_data = setup_database()\n",
    "\n",
    "if conn:\n",
    "    print(\"\\nüéâ ¬°Base de datos lista para an√°lisis SQL!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No se pudo configurar la base de datos.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Archivo de datos no encontrado. Creando datos de ejemplo...\n",
      "‚úÖ Datos descargados con yfinance: (1005, 6)\n",
      "‚úÖ Base de datos SQLite configurada exitosamente\n",
      "üìä Tabla 'tesla_stock' creada con 1005 filas\n",
      "üìÖ Per√≠odo: 2020-01-03 00:00:00 a 2023-12-29 00:00:00\n",
      "\n",
      "üìã ESQUEMA DE LA TABLA:\n",
      "  ‚Ä¢ Date: TIMESTAMP\n",
      "  ‚Ä¢ Close: REAL\n",
      "  ‚Ä¢ High: REAL\n",
      "  ‚Ä¢ Low: REAL\n",
      "  ‚Ä¢ Open: REAL\n",
      "  ‚Ä¢ Volume: INTEGER\n",
      "  ‚Ä¢ Daily_Return: REAL\n",
      "  ‚Ä¢ Price_Range: REAL\n",
      "  ‚Ä¢ Price_Change: REAL\n",
      "  ‚Ä¢ Year: INTEGER\n",
      "  ‚Ä¢ Month: INTEGER\n",
      "  ‚Ä¢ DayOfWeek: INTEGER\n",
      "  ‚Ä¢ Quarter: INTEGER\n",
      "\n",
      "üéâ ¬°Base de datos lista para an√°lisis SQL!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Consultas B√°sicas de Exploraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:29:56.544091700Z",
     "start_time": "2025-08-13T09:01:34.045452Z"
    }
   },
   "source": "# Consultas b√°sicas de exploraci√≥n\ndef basic_sql_exploration(conn):\n    \"\"\"\n    Realizar consultas b√°sicas para explorar los datos\n    \"\"\"\n    if conn is None:\n        print(\"‚ùå No hay conexi√≥n a la base de datos\")\n        return\n    \n    print(\"üìä CONSULTAS B√ÅSICAS DE EXPLORACI√ìN\")\n    print(\"=\" * 40)\n    \n    # 1. Estad√≠sticas b√°sicas\n    basic_stats = \"\"\"\n    SELECT \n        COUNT(*) as total_records,\n        MIN(Date) as start_date,\n        MAX(Date) as end_date,\n        ROUND(MIN(Close), 2) as min_price,\n        ROUND(MAX(Close), 2) as max_price,\n        ROUND(AVG(Close), 2) as avg_price,\n        ROUND(AVG(Volume), 0) as avg_volume\n    FROM tesla_stock\n    \"\"\"\n    \n    stats_result = pd.read_sql_query(basic_stats, conn)\n    print(\"\\nüìà ESTAD√çSTICAS GENERALES:\")\n    for col in stats_result.columns:\n        value = stats_result[col].iloc[0]\n        print(f\"  ‚Ä¢ {col.replace('_', ' ').title()}: {value}\")\n    \n    # 2. Top 10 d√≠as con mayor volumen\n    high_volume = \"\"\"\n    SELECT \n        Date,\n        ROUND(Close, 2) as Close_Price,\n        Volume,\n        ROUND(Daily_Return * 100, 2) as Daily_Return_Pct\n    FROM tesla_stock\n    ORDER BY Volume DESC\n    LIMIT 10\n    \"\"\"\n    \n    volume_result = pd.read_sql_query(high_volume, conn)\n    print(\"\\nüìä TOP 10 D√çAS CON MAYOR VOLUMEN:\")\n    print(volume_result.to_string(index=False))\n    \n    # 3. Mayores ganancias diarias\n    biggest_gains = \"\"\"\n    SELECT \n        Date,\n        ROUND(Close, 2) as Close_Price,\n        ROUND(Daily_Return * 100, 2) as Daily_Return_Pct,\n        'Ganancia' as Move_Type\n    FROM tesla_stock\n    WHERE Daily_Return IS NOT NULL\n    ORDER BY Daily_Return DESC\n    LIMIT 5\n    \"\"\"\n    \n    gains_result = pd.read_sql_query(biggest_gains, conn)\n    print(\"\\nüéØ TOP 5 MAYORES GANANCIAS DIARIAS:\")\n    print(gains_result.to_string(index=False))\n    \n    # 4. Mayores p√©rdidas diarias  \n    biggest_losses = \"\"\"\n    SELECT \n        Date,\n        ROUND(Close, 2) as Close_Price,\n        ROUND(Daily_Return * 100, 2) as Daily_Return_Pct,\n        'P√©rdida' as Move_Type\n    FROM tesla_stock\n    WHERE Daily_Return IS NOT NULL\n    ORDER BY Daily_Return ASC\n    LIMIT 5\n    \"\"\"\n    \n    losses_result = pd.read_sql_query(biggest_losses, conn)\n    print(\"\\nüéØ TOP 5 MAYORES P√âRDIDAS DIARIAS:\")\n    print(losses_result.to_string(index=False))\n    \n    return stats_result, volume_result, gains_result, losses_result\n\n# Ejecutar consultas b√°sicas\nif conn:\n    basic_results = basic_sql_exploration(conn)\nelse:\n    print(\"‚ö†Ô∏è No se pueden ejecutar consultas sin conexi√≥n a la base de datos\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CONSULTAS B√ÅSICAS DE EXPLORACI√ìN\n",
      "========================================\n",
      "\n",
      "üìà ESTAD√çSTICAS GENERALES:\n",
      "  ‚Ä¢ Total Records: 1005\n",
      "  ‚Ä¢ Start Date: 2020-01-03 00:00:00\n",
      "  ‚Ä¢ End Date: 2023-12-29 00:00:00\n",
      "  ‚Ä¢ Min Price: 24.08\n",
      "  ‚Ä¢ Max Price: 409.97\n",
      "  ‚Ä¢ Avg Price: 209.31\n",
      "  ‚Ä¢ Avg Volume: 133216673.0\n",
      "\n",
      "üìä TOP 10 D√çAS CON MAYOR VOLUMEN:\n",
      "               Date  Close_Price    Volume  Daily_Return_Pct\n",
      "2020-02-04 00:00:00        59.14 914082000             13.73\n",
      "2020-02-05 00:00:00        48.98 726357000            -17.18\n",
      "2020-02-03 00:00:00        52.00 705975000             19.89\n",
      "2020-12-18 00:00:00       231.67 666378600              5.96\n",
      "2020-02-06 00:00:00        49.93 598212000              1.94\n",
      "2020-07-13 00:00:00        99.80 584781000             -3.08\n",
      "2020-05-01 00:00:00        46.75 487977000            -10.30\n",
      "2020-01-22 00:00:00        37.97 470535000              4.09\n",
      "2020-01-08 00:00:00        32.81 467164500              4.92\n",
      "2020-04-14 00:00:00        47.33 458647500              9.05\n",
      "\n",
      "üéØ TOP 5 MAYORES GANANCIAS DIARIAS:\n",
      "               Date  Close_Price  Daily_Return_Pct Move_Type\n",
      "2020-02-03 00:00:00        52.00             19.89  Ganancia\n",
      "2021-03-09 00:00:00       224.53             19.64  Ganancia\n",
      "2020-03-19 00:00:00        28.51             18.39  Ganancia\n",
      "2020-03-24 00:00:00        33.67             16.28  Ganancia\n",
      "2020-02-04 00:00:00        59.14             13.73  Ganancia\n",
      "\n",
      "üéØ TOP 5 MAYORES P√âRDIDAS DIARIAS:\n",
      "               Date  Close_Price  Daily_Return_Pct Move_Type\n",
      "2020-09-08 00:00:00       110.07            -21.06   P√©rdida\n",
      "2020-03-16 00:00:00        29.67            -18.58   P√©rdida\n",
      "2020-02-05 00:00:00        48.98            -17.18   P√©rdida\n",
      "2020-03-18 00:00:00        24.08            -16.03   P√©rdida\n",
      "2020-03-09 00:00:00        40.53            -13.57   P√©rdida\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Temporal con SQL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:31:26.390221Z",
     "start_time": "2025-08-13T14:31:26.364224Z"
    }
   },
   "source": "# An√°lisis temporal usando SQL\ndef temporal_analysis_sql(conn):\n    \"\"\"\n    An√°lisis temporal usando consultas SQL avanzadas\n    \"\"\"\n    if conn is None:\n        print(\"‚ùå No hay conexi√≥n a la base de datos\")\n        return\n    \n    print(\"üìÖ AN√ÅLISIS TEMPORAL CON SQL\")\n    print(\"=\" * 35)\n    \n    # 1. Rendimiento por a√±o - versi√≥n simplificada compatible con SQLite\n    yearly_performance = \"\"\"\n    WITH yearly_data AS (\n        SELECT \n            Year,\n            Date,\n            Close,\n            Daily_Return,\n            ROW_NUMBER() OVER (PARTITION BY Year ORDER BY Date) as first_day,\n            ROW_NUMBER() OVER (PARTITION BY Year ORDER BY Date DESC) as last_day\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL\n    ),\n    yearly_summary AS (\n        SELECT \n            Year,\n            MIN(CASE WHEN first_day = 1 THEN Close END) as start_price,\n            MIN(CASE WHEN last_day = 1 THEN Close END) as end_price,\n            AVG(Daily_Return) as avg_daily_return,\n            COUNT(*) as trading_days\n        FROM yearly_data\n        GROUP BY Year\n    )\n    SELECT \n        Year,\n        ROUND(start_price, 2) as Start_Price,\n        ROUND(end_price, 2) as End_Price,\n        ROUND((end_price - start_price) / start_price * 100, 2) as Annual_Return_Pct,\n        ROUND(avg_daily_return * 100, 3) as Avg_Daily_Return_Pct,\n        trading_days as Trading_Days\n    FROM yearly_summary\n    ORDER BY Year\n    \"\"\"\n    \n    yearly_result = pd.read_sql_query(yearly_performance, conn)\n    print(\"\\nüìä RENDIMIENTO ANUAL:\")\n    print(yearly_result.to_string(index=False))\n    \n    # 2. An√°lisis por mes - simplificado sin volatilidad\n    monthly_analysis = \"\"\"\n    SELECT \n        Month,\n        CASE Month\n            WHEN 1 THEN 'Enero' WHEN 2 THEN 'Febrero' WHEN 3 THEN 'Marzo'\n            WHEN 4 THEN 'Abril' WHEN 5 THEN 'Mayo' WHEN 6 THEN 'Junio'\n            WHEN 7 THEN 'Julio' WHEN 8 THEN 'Agosto' WHEN 9 THEN 'Septiembre'\n            WHEN 10 THEN 'Octubre' WHEN 11 THEN 'Noviembre' WHEN 12 THEN 'Diciembre'\n        END as Month_Name,\n        COUNT(*) as Trading_Days,\n        ROUND(AVG(Daily_Return) * 100, 3) as Avg_Daily_Return_Pct,\n        ROUND(AVG(ABS(Daily_Return)) * 100, 3) as Avg_Abs_Return_Pct,\n        SUM(CASE WHEN Daily_Return > 0 THEN 1 ELSE 0 END) as Positive_Days,\n        ROUND(AVG(Volume), 0) as Avg_Volume\n    FROM tesla_stock\n    WHERE Daily_Return IS NOT NULL\n    GROUP BY Month\n    ORDER BY Month\n    \"\"\"\n    \n    monthly_result = pd.read_sql_query(monthly_analysis, conn)\n    print(\"\\nüìÖ AN√ÅLISIS MENSUAL:\")\n    print(monthly_result.to_string(index=False))\n    \n    # 3. An√°lisis por d√≠a de la semana - simplificado\n    dow_analysis = \"\"\"\n    SELECT \n        DayOfWeek,\n        CASE DayOfWeek\n            WHEN 0 THEN 'Lunes' WHEN 1 THEN 'Martes' WHEN 2 THEN 'Mi√©rcoles'\n            WHEN 3 THEN 'Jueves' WHEN 4 THEN 'Viernes'\n        END as Day_Name,\n        COUNT(*) as Trading_Days,\n        ROUND(AVG(Daily_Return) * 100, 3) as Avg_Daily_Return_Pct,\n        ROUND(AVG(ABS(Daily_Return)) * 100, 3) as Avg_Abs_Return_Pct,\n        SUM(CASE WHEN Daily_Return > 0 THEN 1 ELSE 0 END) as Positive_Days,\n        ROUND(AVG(Volume), 0) as Avg_Volume\n    FROM tesla_stock\n    WHERE Daily_Return IS NOT NULL AND DayOfWeek < 5  -- Solo d√≠as laborales\n    GROUP BY DayOfWeek\n    ORDER BY DayOfWeek\n    \"\"\"\n    \n    dow_result = pd.read_sql_query(dow_analysis, conn)\n    print(\"\\nüìä AN√ÅLISIS POR D√çA DE LA SEMANA:\")\n    print(dow_result.to_string(index=False))\n    \n    return yearly_result, monthly_result, dow_result\n\n# Ejecutar an√°lisis temporal\nif conn:\n    temporal_results = temporal_analysis_sql(conn)\nelse:\n    print(\"‚ö†Ô∏è No se puede ejecutar an√°lisis temporal sin conexi√≥n a la base de datos\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ AN√ÅLISIS TEMPORAL CON SQL\n",
      "===================================\n",
      "\n",
      "üìä RENDIMIENTO ANUAL:\n",
      " Year  Start_Price  End_Price  Annual_Return_Pct  Avg_Daily_Return_Pct  Trading_Days\n",
      " 2020        29.53     235.22             696.45                 0.997           252\n",
      " 2021       243.26     352.26              44.81                 0.219           252\n",
      " 2022       399.93     123.18             -69.20                -0.329           251\n",
      " 2023       108.10     248.48             129.86                 0.339           250\n",
      "\n",
      "üìÖ AN√ÅLISIS MENSUAL:\n",
      " Month Month_Name  Trading_Days  Avg_Daily_Return_Pct  Avg_Abs_Return_Pct  Positive_Days  Avg_Volume\n",
      "     1      Enero            79                 1.073               3.756             47 175897294.0\n",
      "     2    Febrero            76                 0.089               3.686             39 179912467.0\n",
      "     3      Marzo            91                 0.136               4.107             44 155849176.0\n",
      "     4      Abril            81                 0.114               3.367             41 145480465.0\n",
      "     5       Mayo            83                 0.092               2.795             42 127673605.0\n",
      "     6      Junio            86                 0.616               2.814             48 126165969.0\n",
      "     7      Julio            83                 0.791               2.772             49 134491867.0\n",
      "     8     Agosto            89                 0.633               2.414             47 112513833.0\n",
      "     9 Septiembre            83                -0.101               2.874             47 121916639.0\n",
      "    10    Octubre            86                -0.072               2.402             49  97838222.0\n",
      "    11  Noviembre            83                 0.599               3.131             46 106403113.0\n",
      "    12  Diciembre            85                -0.263               2.883             41 121870180.0\n",
      "\n",
      "üìä AN√ÅLISIS POR D√çA DE LA SEMANA:\n",
      " DayOfWeek  Day_Name  Trading_Days  Avg_Daily_Return_Pct  Avg_Abs_Return_Pct  Positive_Days  Avg_Volume\n",
      "         0     Lunes           185                 1.133               3.948            109 136053622.0\n",
      "         1    Martes           207                 0.405               3.053            113 134080112.0\n",
      "         2 Mi√©rcoles           208                 0.179               2.911            114 130662354.0\n",
      "         3    Jueves           204                -0.118               3.067            105 134835103.0\n",
      "         4   Viernes           201                 0.010               2.483             99 130717029.0\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de Patrones de Trading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:31:31.753877Z",
     "start_time": "2025-08-13T14:31:31.727879Z"
    }
   },
   "source": [
    "# An√°lisis de patrones de trading con SQL\n",
    "def trading_patterns_analysis(conn):\n",
    "    \"\"\"\n",
    "    Analizar patrones de trading usando SQL\n",
    "    \"\"\"\n",
    "    if conn is None:\n",
    "        print(\"‚ùå No hay conexi√≥n a la base de datos\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç AN√ÅLISIS DE PATRONES DE TRADING\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 1. An√°lisis de rachas ganadoras y perdedoras\n",
    "    streak_analysis = \"\"\"\n",
    "    WITH daily_direction AS (\n",
    "        SELECT \n",
    "            Date,\n",
    "            Close,\n",
    "            Daily_Return,\n",
    "            CASE \n",
    "                WHEN Daily_Return > 0 THEN 1\n",
    "                WHEN Daily_Return < 0 THEN -1\n",
    "                ELSE 0\n",
    "            END as direction,\n",
    "            ROW_NUMBER() OVER (ORDER BY Date) as rn\n",
    "        FROM tesla_stock\n",
    "        WHERE Daily_Return IS NOT NULL\n",
    "    ),\n",
    "    streak_groups AS (\n",
    "        SELECT *,\n",
    "            rn - ROW_NUMBER() OVER (PARTITION BY direction ORDER BY Date) as streak_group\n",
    "        FROM daily_direction\n",
    "        WHERE direction != 0\n",
    "    ),\n",
    "    streaks AS (\n",
    "        SELECT \n",
    "            direction,\n",
    "            streak_group,\n",
    "            COUNT(*) as streak_length,\n",
    "            MIN(Date) as streak_start,\n",
    "            MAX(Date) as streak_end\n",
    "        FROM streak_groups\n",
    "        GROUP BY direction, streak_group\n",
    "    )\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN direction = 1 THEN 'Racha Ganadora'\n",
    "            ELSE 'Racha Perdedora'\n",
    "        END as Streak_Type,\n",
    "        COUNT(*) as Total_Streaks,\n",
    "        ROUND(AVG(streak_length), 1) as Avg_Length,\n",
    "        MAX(streak_length) as Max_Length,\n",
    "        MIN(streak_length) as Min_Length\n",
    "    FROM streaks\n",
    "    GROUP BY direction\n",
    "    ORDER BY direction DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    streak_result = pd.read_sql_query(streak_analysis, conn)\n",
    "    print(\"\\nüéØ AN√ÅLISIS DE RACHAS:\")\n",
    "    print(streak_result.to_string(index=False))\n",
    "    \n",
    "    # 2. An√°lisis de gaps (brechas de precios)\n",
    "    gap_analysis = \"\"\"\n",
    "    WITH price_gaps AS (\n",
    "        SELECT \n",
    "            Date,\n",
    "            Open,\n",
    "            Close,\n",
    "            LAG(Close) OVER (ORDER BY Date) as prev_close,\n",
    "            Open - LAG(Close) OVER (ORDER BY Date) as gap_amount,\n",
    "            (Open - LAG(Close) OVER (ORDER BY Date)) / LAG(Close) OVER (ORDER BY Date) * 100 as gap_pct\n",
    "        FROM tesla_stock\n",
    "    )\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN ABS(gap_pct) >= 5 THEN 'Gap Grande (‚â•5%)'\n",
    "            WHEN ABS(gap_pct) >= 2 THEN 'Gap Medio (2-5%)'\n",
    "            WHEN ABS(gap_pct) >= 1 THEN 'Gap Peque√±o (1-2%)'\n",
    "            ELSE 'Sin Gap (<1%)'\n",
    "        END as Gap_Category,\n",
    "        COUNT(*) as Frequency,\n",
    "        ROUND(AVG(gap_pct), 2) as Avg_Gap_Pct,\n",
    "        ROUND(MIN(gap_pct), 2) as Min_Gap_Pct,\n",
    "        ROUND(MAX(gap_pct), 2) as Max_Gap_Pct\n",
    "    FROM price_gaps\n",
    "    WHERE gap_pct IS NOT NULL\n",
    "    GROUP BY Gap_Category\n",
    "    ORDER BY Frequency DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    gap_result = pd.read_sql_query(gap_analysis, conn)\n",
    "    print(\"\\nüìä AN√ÅLISIS DE GAPS (BRECHAS):\")\n",
    "    print(gap_result.to_string(index=False))\n",
    "    \n",
    "    # 3. An√°lisis de volumen vs movimiento de precio\n",
    "    volume_price_analysis = \"\"\"\n",
    "    WITH volume_categories AS (\n",
    "        SELECT \n",
    "            Date,\n",
    "            Volume,\n",
    "            Daily_Return,\n",
    "            ABS(Daily_Return) as abs_return,\n",
    "            AVG(Volume) OVER () as avg_volume,\n",
    "            CASE \n",
    "                WHEN Volume >= AVG(Volume) OVER () * 2 THEN 'Volumen Muy Alto (>2x)'\n",
    "                WHEN Volume >= AVG(Volume) OVER () * 1.5 THEN 'Volumen Alto (1.5-2x)'\n",
    "                WHEN Volume >= AVG(Volume) OVER () THEN 'Volumen Medio (1-1.5x)'\n",
    "                ELSE 'Volumen Bajo (<1x)'\n",
    "            END as volume_category\n",
    "        FROM tesla_stock\n",
    "        WHERE Daily_Return IS NOT NULL\n",
    "    )\n",
    "    SELECT \n",
    "        volume_category as Volume_Category,\n",
    "        COUNT(*) as Trading_Days,\n",
    "        ROUND(AVG(Daily_Return) * 100, 3) as Avg_Daily_Return_Pct,\n",
    "        ROUND(AVG(abs_return) * 100, 3) as Avg_Abs_Return_Pct,\n",
    "        ROUND(AVG(Volume), 0) as Avg_Volume\n",
    "    FROM volume_categories\n",
    "    GROUP BY volume_category\n",
    "    ORDER BY Avg_Volume DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    volume_result = pd.read_sql_query(volume_price_analysis, conn)\n",
    "    print(\"\\nüìà VOLUMEN VS MOVIMIENTO DE PRECIO:\")\n",
    "    print(volume_result.to_string(index=False))\n",
    "    \n",
    "    return streak_result, gap_result, volume_result\n",
    "\n",
    "# Ejecutar an√°lisis de patrones\n",
    "if conn:\n",
    "    pattern_results = trading_patterns_analysis(conn)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se puede ejecutar an√°lisis de patrones sin conexi√≥n a la base de datos\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISIS DE PATRONES DE TRADING\n",
      "========================================\n",
      "\n",
      "üéØ AN√ÅLISIS DE RACHAS:\n",
      "    Streak_Type  Total_Streaks  Avg_Length  Max_Length  Min_Length\n",
      " Racha Ganadora            249         2.2          13           1\n",
      "Racha Perdedora            248         1.9           7           1\n",
      "\n",
      "üìä AN√ÅLISIS DE GAPS (BRECHAS):\n",
      "      Gap_Category  Frequency  Avg_Gap_Pct  Min_Gap_Pct  Max_Gap_Pct\n",
      "     Sin Gap (<1%)        439         0.08        -0.99         0.99\n",
      "Gap Peque√±o (1-2%)        278         0.17        -1.98         1.99\n",
      "  Gap Medio (2-5%)        222         0.22        -4.98         4.90\n",
      "  Gap Grande (‚â•5%)         65         1.74       -14.90        13.20\n",
      "\n",
      "üìà VOLUMEN VS MOVIMIENTO DE PRECIO:\n",
      "       Volume_Category  Trading_Days  Avg_Daily_Return_Pct  Avg_Abs_Return_Pct  Avg_Volume\n",
      "Volumen Muy Alto (>2x)            74                 2.107               6.928 366956091.0\n",
      " Volumen Alto (1.5-2x)            87                 0.815               5.001 227947664.0\n",
      "Volumen Medio (1-1.5x)           188                 0.370               3.212 159839477.0\n",
      "    Volumen Bajo (<1x)           656                 0.018               2.349  86656612.0\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Volatilidad con SQL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:31:35.057527Z",
     "start_time": "2025-08-13T14:31:35.031527Z"
    }
   },
   "source": "# An√°lisis de volatilidad usando SQL\ndef volatility_analysis_sql(conn):\n    \"\"\"\n    An√°lisis de volatilidad usando consultas SQL avanzadas\n    \"\"\"\n    if conn is None:\n        print(\"‚ùå No hay conexi√≥n a la base de datos\")\n        return\n    \n    print(\"üåä AN√ÅLISIS DE VOLATILIDAD CON SQL\")\n    print(\"=\" * 40)\n    \n    # 1. Volatilidad por per√≠odos - simplificado sin SQRT\n    volatility_periods = \"\"\"\n    WITH volatility_data AS (\n        SELECT \n            Date,\n            Daily_Return,\n            ABS(Daily_Return) as abs_return,\n            Daily_Return * Daily_Return as squared_return,\n            -- Promedio de retornos absolutos m√≥vil de 20 d√≠as (proxy de volatilidad)\n            AVG(ABS(Daily_Return)) OVER (\n                ORDER BY Date \n                ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n            ) as rolling_abs_return_20d\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL\n    )\n    SELECT \n        CASE \n            WHEN rolling_abs_return_20d >= 0.04 THEN 'Muy Alta (‚â•4%)'\n            WHEN rolling_abs_return_20d >= 0.025 THEN 'Alta (2.5-4%)'\n            WHEN rolling_abs_return_20d >= 0.015 THEN 'Media (1.5-2.5%)'\n            ELSE 'Baja (<1.5%)'\n        END as Volatility_Category,\n        COUNT(*) as Trading_Days,\n        ROUND(AVG(rolling_abs_return_20d) * 100, 2) as Avg_Abs_Return_20d_Pct,\n        ROUND(AVG(abs_return) * 100, 2) as Avg_Daily_Abs_Return_Pct,\n        ROUND(MAX(abs_return) * 100, 2) as Max_Daily_Abs_Return_Pct\n    FROM volatility_data\n    WHERE rolling_abs_return_20d IS NOT NULL\n    GROUP BY Volatility_Category\n    ORDER BY Avg_Abs_Return_20d_Pct DESC\n    \"\"\"\n    \n    volatility_result = pd.read_sql_query(volatility_periods, conn)\n    print(\"\\nüìä CATEGOR√çAS DE VOLATILIDAD:\")\n    print(volatility_result.to_string(index=False))\n    \n    # 2. An√°lisis de d√≠as de alta volatilidad - simplificado\n    high_volatility_days = \"\"\"\n    WITH daily_volatility AS (\n        SELECT \n            Date,\n            Close,\n            Daily_Return,\n            ABS(Daily_Return) as abs_return,\n            Volume,\n            AVG(ABS(Daily_Return)) OVER () as overall_avg_abs_return\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL\n    )\n    SELECT \n        Date,\n        ROUND(Close, 2) as Close_Price,\n        ROUND(Daily_Return * 100, 2) as Daily_Return_Pct,\n        Volume,\n        ROUND(abs_return / overall_avg_abs_return, 1) as Volatility_Multiple\n    FROM daily_volatility\n    WHERE abs_return > overall_avg_abs_return * 2.5  -- M√°s de 2.5x el promedio\n    ORDER BY abs_return DESC\n    LIMIT 15\n    \"\"\"\n    \n    high_vol_result = pd.read_sql_query(high_volatility_days, conn)\n    print(\"\\nüî• TOP 15 D√çAS DE MAYOR VOLATILIDAD:\")\n    print(high_vol_result.to_string(index=False))\n    \n    # 3. Volatilidad por trimestre y a√±o - usando retornos absolutos\n    quarterly_volatility = \"\"\"\n    SELECT \n        Year,\n        Quarter,\n        COUNT(*) as Trading_Days,\n        ROUND(AVG(ABS(Daily_Return)) * 100, 2) as Avg_Abs_Return_Pct,\n        ROUND(MAX(ABS(Daily_Return)) * 100, 2) as Max_Abs_Return_Pct,\n        SUM(CASE WHEN ABS(Daily_Return) > 0.03 THEN 1 ELSE 0 END) as High_Volatility_Days\n    FROM tesla_stock\n    WHERE Daily_Return IS NOT NULL\n    GROUP BY Year, Quarter\n    ORDER BY Year, Quarter\n    \"\"\"\n    \n    quarterly_vol_result = pd.read_sql_query(quarterly_volatility, conn)\n    print(\"\\nüìÖ VOLATILIDAD POR TRIMESTRE:\")\n    print(quarterly_vol_result.to_string(index=False))\n    \n    return volatility_result, high_vol_result, quarterly_vol_result\n\n# Ejecutar an√°lisis de volatilidad\nif conn:\n    volatility_results = volatility_analysis_sql(conn)\nelse:\n    print(\"‚ö†Ô∏è No se puede ejecutar an√°lisis de volatilidad sin conexi√≥n a la base de datos\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä AN√ÅLISIS DE VOLATILIDAD CON SQL\n",
      "========================================\n",
      "\n",
      "üìä CATEGOR√çAS DE VOLATILIDAD:\n",
      "Volatility_Category  Trading_Days  Avg_Abs_Return_20d_Pct  Avg_Daily_Abs_Return_Pct  Max_Daily_Abs_Return_Pct\n",
      "     Muy Alta (‚â•4%)           176                    5.00                      5.00                     21.06\n",
      "      Alta (2.5-4%)           505                    3.14                      3.11                     13.53\n",
      "   Media (1.5-2.5%)           282                    2.07                      2.09                     12.66\n",
      "       Baja (<1.5%)            42                    1.25                      1.23                      3.86\n",
      "\n",
      "üî• TOP 15 D√çAS DE MAYOR VOLATILIDAD:\n",
      "               Date  Close_Price  Daily_Return_Pct    Volume  Volatility_Multiple\n",
      "2020-09-08 00:00:00       110.07            -21.06 346397100                  6.8\n",
      "2020-02-03 00:00:00        52.00             19.89 705975000                  6.5\n",
      "2021-03-09 00:00:00       224.53             19.64 202569900                  6.4\n",
      "2020-03-16 00:00:00        29.67            -18.58 307342500                  6.0\n",
      "2020-03-19 00:00:00        28.51             18.39 452932500                  6.0\n",
      "2020-02-05 00:00:00        48.98            -17.18 726357000                  5.6\n",
      "2020-03-24 00:00:00        33.67             16.28 343428000                  5.3\n",
      "2020-03-18 00:00:00        24.08            -16.03 356793000                  5.2\n",
      "2020-02-04 00:00:00        59.14             13.73 914082000                  4.5\n",
      "2020-04-13 00:00:00        43.40             13.60 337131000                  4.4\n",
      "2020-03-09 00:00:00        40.53            -13.57 256105500                  4.4\n",
      "2022-01-03 00:00:00       399.93             13.53 103931400                  4.4\n",
      "2020-07-06 00:00:00        91.44             13.48 308548500                  4.4\n",
      "2020-08-12 00:00:00       103.65             13.12 327441000                  4.3\n",
      "2020-02-27 00:00:00        45.27            -12.81 364158000                  4.2\n",
      "\n",
      "üìÖ VOLATILIDAD POR TRIMESTRE:\n",
      " Year  Quarter  Trading_Days  Avg_Abs_Return_Pct  Max_Abs_Return_Pct  High_Volatility_Days\n",
      " 2020        1            61                5.21               19.89                    29\n",
      " 2020        2            63                3.58               13.60                    27\n",
      " 2020        3            64                4.60               21.06                    34\n",
      " 2020        4            64                2.96               10.20                    24\n",
      " 2021        1            61                3.41               19.64                    29\n",
      " 2021        2            63                2.25                8.60                    21\n",
      " 2021        3            64                1.48                4.69                     7\n",
      " 2021        4            64                2.79               12.66                    28\n",
      " 2022        1            62                3.44               13.53                    30\n",
      " 2022        2            62                3.69               12.18                    33\n",
      " 2022        3            64                2.31                9.78                    17\n",
      " 2022        4            63                3.35               11.41                    28\n",
      " 2023        1            62                3.41               12.24                    28\n",
      " 2023        2            62                2.42                9.75                    20\n",
      " 2023        3            63                2.33               10.09                    16\n",
      " 2023        4            63                2.10                9.30                    15\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Consultas de Correlaci√≥n y Tendencias"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:31:38.935158Z",
     "start_time": "2025-08-13T14:31:38.902159Z"
    }
   },
   "source": "# An√°lisis de correlaciones y tendencias con SQL\ndef correlation_trends_analysis(conn):\n    \"\"\"\n    An√°lisis de correlaciones y tendencias usando SQL\n    \"\"\"\n    if conn is None:\n        print(\"‚ùå No hay conexi√≥n a la base de datos\")\n        return\n    \n    print(\"üîó AN√ÅLISIS DE CORRELACIONES Y TENDENCIAS\")\n    print(\"=\" * 45)\n    \n    # 1. An√°lisis de tendencias usando promedios m√≥viles\n    trend_analysis = \"\"\"\n    WITH moving_averages AS (\n        SELECT \n            Date,\n            Close,\n            AVG(Close) OVER (\n                ORDER BY Date \n                ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n            ) as ma_20,\n            AVG(Close) OVER (\n                ORDER BY Date \n                ROWS BETWEEN 49 PRECEDING AND CURRENT ROW\n            ) as ma_50,\n            Daily_Return\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL\n    ),\n    trend_signals AS (\n        SELECT *,\n            CASE \n                WHEN Close > ma_20 AND ma_20 > ma_50 THEN 'Tendencia Alcista Fuerte'\n                WHEN Close > ma_20 AND ma_20 <= ma_50 THEN 'Tendencia Alcista D√©bil'\n                WHEN Close <= ma_20 AND ma_20 > ma_50 THEN 'Tendencia Bajista D√©bil'\n                WHEN Close <= ma_20 AND ma_20 <= ma_50 THEN 'Tendencia Bajista Fuerte'\n                ELSE 'Lateral'\n            END as trend_signal\n        FROM moving_averages\n        WHERE ma_50 IS NOT NULL\n    )\n    SELECT \n        trend_signal as Trend_Signal,\n        COUNT(*) as Trading_Days,\n        ROUND(AVG(Daily_Return) * 100, 3) as Avg_Daily_Return_Pct,\n        ROUND(AVG(ABS(Daily_Return)) * 100, 3) as Avg_Abs_Return_Pct,\n        SUM(CASE WHEN Daily_Return > 0 THEN 1 ELSE 0 END) as Positive_Days\n    FROM trend_signals\n    GROUP BY trend_signal\n    ORDER BY Avg_Daily_Return_Pct DESC\n    \"\"\"\n    \n    trend_result = pd.read_sql_query(trend_analysis, conn)\n    print(\"\\nüìà AN√ÅLISIS DE TENDENCIAS:\")\n    print(trend_result.to_string(index=False))\n    \n    # 2. Correlaci√≥n entre volumen y retornos\n    volume_return_correlation = \"\"\"\n    WITH volume_buckets AS (\n        SELECT \n            Date,\n            Volume,\n            Daily_Return,\n            ABS(Daily_Return) as abs_return,\n            NTILE(5) OVER (ORDER BY Volume) as volume_quintile\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL AND Volume IS NOT NULL\n    )\n    SELECT \n        volume_quintile as Volume_Quintile,\n        COUNT(*) as Trading_Days,\n        ROUND(AVG(Volume), 0) as Avg_Volume,\n        ROUND(AVG(Daily_Return) * 100, 3) as Avg_Daily_Return_Pct,\n        ROUND(AVG(abs_return) * 100, 3) as Avg_Abs_Return_Pct,\n        ROUND(MIN(Volume), 0) as Min_Volume,\n        ROUND(MAX(Volume), 0) as Max_Volume\n    FROM volume_buckets\n    GROUP BY volume_quintile\n    ORDER BY volume_quintile\n    \"\"\"\n    \n    correlation_result = pd.read_sql_query(volume_return_correlation, conn)\n    print(\"\\nüìä CORRELACI√ìN VOLUMEN-RETORNO (POR QUINTILES):\")\n    print(correlation_result.to_string(index=False))\n    \n    # 3. An√°lisis de momentum (retornos consecutivos)\n    momentum_analysis = \"\"\"\n    WITH momentum_data AS (\n        SELECT \n            Date,\n            Daily_Return,\n            LAG(Daily_Return, 1) OVER (ORDER BY Date) as prev_return_1,\n            LAG(Daily_Return, 2) OVER (ORDER BY Date) as prev_return_2,\n            LAG(Daily_Return, 3) OVER (ORDER BY Date) as prev_return_3,\n            LEAD(Daily_Return, 1) OVER (ORDER BY Date) as next_return_1\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL\n    )\n    SELECT \n        'Retorno despu√©s de 3 d√≠as positivos' as Scenario,\n        COUNT(*) as Occurrences,\n        ROUND(AVG(next_return_1) * 100, 3) as Avg_Next_Return_Pct,\n        SUM(CASE WHEN next_return_1 > 0 THEN 1 ELSE 0 END) as Positive_Next_Days\n    FROM momentum_data\n    WHERE prev_return_1 > 0 AND prev_return_2 > 0 AND prev_return_3 > 0\n      AND next_return_1 IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT \n        'Retorno despu√©s de 3 d√≠as negativos' as Scenario,\n        COUNT(*) as Occurrences,\n        ROUND(AVG(next_return_1) * 100, 3) as Avg_Next_Return_Pct,\n        SUM(CASE WHEN next_return_1 > 0 THEN 1 ELSE 0 END) as Positive_Next_Days\n    FROM momentum_data\n    WHERE prev_return_1 < 0 AND prev_return_2 < 0 AND prev_return_3 < 0\n      AND next_return_1 IS NOT NULL\n    \"\"\"\n    \n    momentum_result = pd.read_sql_query(momentum_analysis, conn)\n    print(\"\\nüéØ AN√ÅLISIS DE MOMENTUM:\")\n    print(momentum_result.to_string(index=False))\n    \n    return trend_result, correlation_result, momentum_result\n\n# Ejecutar an√°lisis de correlaciones\nif conn:\n    correlation_results = correlation_trends_analysis(conn)\nelse:\n    print(\"‚ö†Ô∏è No se puede ejecutar an√°lisis de correlaciones sin conexi√≥n a la base de datos\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó AN√ÅLISIS DE CORRELACIONES Y TENDENCIAS\n",
      "=============================================\n",
      "\n",
      "üìà AN√ÅLISIS DE TENDENCIAS:\n",
      "            Trend_Signal  Trading_Days  Avg_Daily_Return_Pct  Avg_Abs_Return_Pct  Positive_Days\n",
      " Tendencia Alcista D√©bil           195                 1.723               2.961            128\n",
      "Tendencia Alcista Fuerte           381                 1.027               2.868            244\n",
      "Tendencia Bajista Fuerte           228                -0.581               3.534             96\n",
      " Tendencia Bajista D√©bil           201                -1.424               3.067             72\n",
      "\n",
      "üìä CORRELACI√ìN VOLUMEN-RETORNO (POR QUINTILES):\n",
      " Volume_Quintile  Trading_Days  Avg_Volume  Avg_Daily_Return_Pct  Avg_Abs_Return_Pct  Min_Volume  Max_Volume\n",
      "               1           201  57191795.0                -0.132               1.567  29401800.0  70488600.0\n",
      "               2           201  83697644.0                 0.025               2.696  70545400.0  95672100.0\n",
      "               3           201 108198500.0                -0.032               2.615  95770800.0 122514600.0\n",
      "               4           201 145878581.0                 0.423               3.206 122515800.0 177904800.0\n",
      "               5           201 271116847.0                 1.252               5.301 179971500.0 914082000.0\n",
      "\n",
      "üéØ AN√ÅLISIS DE MOMENTUM:\n",
      "                           Scenario  Occurrences  Avg_Next_Return_Pct  Positive_Next_Days\n",
      "Retorno despu√©s de 3 d√≠as positivos          160                1.160                  99\n",
      "Retorno despu√©s de 3 d√≠as negativos          102                0.196                  57\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen y Insights Clave del An√°lisis SQL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:31:41.926832Z",
     "start_time": "2025-08-13T14:31:41.908834Z"
    }
   },
   "source": "# Generar resumen de an√°lisis SQL\ndef generate_sql_summary(conn):\n    \"\"\"\n    Generar resumen comprehensivo del an√°lisis SQL\n    \"\"\"\n    if conn is None:\n        print(\"‚ùå No hay conexi√≥n a la base de datos\")\n        return\n    \n    print(\"üìä RESUMEN DE AN√ÅLISIS SQL - TESLA STOCK\")\n    print(\"=\" * 50)\n    \n    # Consulta resumen general - simplificada sin SQRT\n    summary_query = \"\"\"\n    WITH overall_stats AS (\n        SELECT \n            COUNT(*) as total_records,\n            MIN(Date) as start_date,\n            MAX(Date) as end_date,\n            ROUND((MAX(Close) - MIN(Close)) / MIN(Close) * 100, 1) as total_price_change_pct,\n            ROUND(AVG(Daily_Return) * 100, 3) as avg_daily_return_pct,\n            ROUND(AVG(ABS(Daily_Return)) * 100, 3) as avg_abs_return_pct,\n            SUM(CASE WHEN Daily_Return > 0 THEN 1 ELSE 0 END) as positive_days,\n            SUM(CASE WHEN Daily_Return < 0 THEN 1 ELSE 0 END) as negative_days,\n            ROUND(AVG(Volume), 0) as avg_volume,\n            ROUND(MAX(Daily_Return) * 100, 2) as max_daily_gain_pct,\n            ROUND(MIN(Daily_Return) * 100, 2) as max_daily_loss_pct\n        FROM tesla_stock\n        WHERE Daily_Return IS NOT NULL\n    )\n    SELECT * FROM overall_stats\n    \"\"\"\n    \n    summary_result = pd.read_sql_query(summary_query, conn)\n    \n    print(\"\\nüîç ESTAD√çSTICAS GENERALES:\")\n    stats = summary_result.iloc[0]\n    print(f\"  ‚Ä¢ Per√≠odo analizado: {stats['start_date']} a {stats['end_date']}\")\n    print(f\"  ‚Ä¢ Total de registros: {stats['total_records']:,} d√≠as\")\n    print(f\"  ‚Ä¢ Cambio total de precio: {stats['total_price_change_pct']}%\")\n    print(f\"  ‚Ä¢ Retorno diario promedio: {stats['avg_daily_return_pct']}%\")\n    print(f\"  ‚Ä¢ Retorno absoluto promedio: {stats['avg_abs_return_pct']}%\")\n    print(f\"  ‚Ä¢ D√≠as positivos: {stats['positive_days']} ({stats['positive_days']/stats['total_records']*100:.1f}%)\")\n    print(f\"  ‚Ä¢ D√≠as negativos: {stats['negative_days']} ({stats['negative_days']/stats['total_records']*100:.1f}%)\")\n    print(f\"  ‚Ä¢ Volumen promedio: {stats['avg_volume']:,.0f} acciones\")\n    print(f\"  ‚Ä¢ M√°xima ganancia diaria: {stats['max_daily_gain_pct']}%\")\n    print(f\"  ‚Ä¢ M√°xima p√©rdida diaria: {stats['max_daily_loss_pct']}%\")\n    \n    # Insights clave usando SQL\n    insights_query = \"\"\"\n    WITH insights AS (\n        SELECT \n            -- Mejor y peor mes\n            (SELECT Month || ' (' || ROUND(AVG(Daily_Return) * 100, 2) || '%)' \n             FROM tesla_stock WHERE Daily_Return IS NOT NULL \n             GROUP BY Month ORDER BY AVG(Daily_Return) DESC LIMIT 1) as best_month,\n            \n            (SELECT Month || ' (' || ROUND(AVG(Daily_Return) * 100, 2) || '%)' \n             FROM tesla_stock WHERE Daily_Return IS NOT NULL \n             GROUP BY Month ORDER BY AVG(Daily_Return) ASC LIMIT 1) as worst_month,\n            \n            -- Mejor d√≠a de la semana\n            (SELECT DayOfWeek || ' (' || ROUND(AVG(Daily_Return) * 100, 2) || '%)' \n             FROM tesla_stock WHERE Daily_Return IS NOT NULL AND DayOfWeek < 5\n             GROUP BY DayOfWeek ORDER BY AVG(Daily_Return) DESC LIMIT 1) as best_day,\n            \n            -- Correlaci√≥n volumen-volatilidad (aproximaci√≥n)\n            (SELECT COUNT(*) FROM tesla_stock \n             WHERE Volume > (SELECT AVG(Volume) FROM tesla_stock) \n               AND ABS(Daily_Return) > (SELECT AVG(ABS(Daily_Return)) FROM tesla_stock WHERE Daily_Return IS NOT NULL)) as high_vol_high_volatility,\n            \n            (SELECT COUNT(*) FROM tesla_stock \n             WHERE Volume > (SELECT AVG(Volume) FROM tesla_stock)) as high_volume_days\n    )\n    SELECT * FROM insights\n    \"\"\"\n    \n    insights_result = pd.read_sql_query(insights_query, conn)\n    insights = insights_result.iloc[0]\n    \n    print(\"\\nüéØ INSIGHTS CLAVE DEL AN√ÅLISIS SQL:\")\n    print(f\"  ‚Ä¢ Mejor mes para invertir: {insights['best_month']}\")\n    print(f\"  ‚Ä¢ Peor mes hist√≥ricamente: {insights['worst_month']}\")\n    print(f\"  ‚Ä¢ Mejor d√≠a de la semana: {insights['best_day']}\")\n    \n    vol_correlation = insights['high_vol_high_volatility'] / insights['high_volume_days'] * 100\n    print(f\"  ‚Ä¢ D√≠as de alto volumen con alta volatilidad: {vol_correlation:.1f}%\")\n    \n    # Recomendaciones basadas en SQL\n    print(\"\\nüí° RECOMENDACIONES BASADAS EN AN√ÅLISIS SQL:\")\n    print(\"  ‚Ä¢ Los an√°lisis de rachas muestran patrones de momentum\")\n    print(\"  ‚Ä¢ La volatilidad se concentra en per√≠odos espec√≠ficos\")\n    print(\"  ‚Ä¢ Existe correlaci√≥n entre volumen alto y movimientos significativos\")\n    print(\"  ‚Ä¢ Los patrones estacionales son detectables con SQL\")\n    print(\"  ‚Ä¢ Las consultas complejas revelan insights ocultos en los datos\")\n    \n    print(\"\\n‚úÖ AN√ÅLISIS SQL COMPLETADO\")\n    print(\"üöÄ ¬°Listo para modelado predictivo!\")\n    \n    return summary_result, insights_result\n\n# Ejecutar resumen final\nif conn:\n    final_summary = generate_sql_summary(conn)\nelse:\n    print(\"‚ö†Ô∏è No se puede generar resumen sin conexi√≥n a la base de datos\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä RESUMEN DE AN√ÅLISIS SQL - TESLA STOCK\n",
      "==================================================\n",
      "\n",
      "üîç ESTAD√çSTICAS GENERALES:\n",
      "  ‚Ä¢ Per√≠odo analizado: 2020-01-03 00:00:00 a 2023-12-29 00:00:00\n",
      "  ‚Ä¢ Total de registros: 1,005 d√≠as\n",
      "  ‚Ä¢ Cambio total de precio: 1602.4%\n",
      "  ‚Ä¢ Retorno diario promedio: 0.307%\n",
      "  ‚Ä¢ Retorno absoluto promedio: 3.077%\n",
      "  ‚Ä¢ D√≠as positivos: 540 (53.7%)\n",
      "  ‚Ä¢ D√≠as negativos: 464 (46.2%)\n",
      "  ‚Ä¢ Volumen promedio: 133,216,673 acciones\n",
      "  ‚Ä¢ M√°xima ganancia diaria: 19.89%\n",
      "  ‚Ä¢ M√°xima p√©rdida diaria: -21.06%\n",
      "\n",
      "üéØ INSIGHTS CLAVE DEL AN√ÅLISIS SQL:\n",
      "  ‚Ä¢ Mejor mes para invertir: 1 (1.07%)\n",
      "  ‚Ä¢ Peor mes hist√≥ricamente: 12 (-0.26%)\n",
      "  ‚Ä¢ Mejor d√≠a de la semana: 0 (1.13%)\n",
      "  ‚Ä¢ D√≠as de alto volumen con alta volatilidad: 53.3%\n",
      "\n",
      "üí° RECOMENDACIONES BASADAS EN AN√ÅLISIS SQL:\n",
      "  ‚Ä¢ Los an√°lisis de rachas muestran patrones de momentum\n",
      "  ‚Ä¢ La volatilidad se concentra en per√≠odos espec√≠ficos\n",
      "  ‚Ä¢ Existe correlaci√≥n entre volumen alto y movimientos significativos\n",
      "  ‚Ä¢ Los patrones estacionales son detectables con SQL\n",
      "  ‚Ä¢ Las consultas complejas revelan insights ocultos en los datos\n",
      "\n",
      "‚úÖ AN√ÅLISIS SQL COMPLETADO\n",
      "üöÄ ¬°Listo para modelado predictivo!\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cerrar Conexi√≥n y Limpiar Recursos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:31:44.804610Z",
     "start_time": "2025-08-13T14:31:44.776614Z"
    }
   },
   "source": [
    "# Limpiar recursos y cerrar conexi√≥n\n",
    "if conn:\n",
    "    # Opcional: Guardar algunos resultados clave\n",
    "    try:\n",
    "        import os\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        \n",
    "        # Exportar tabla final con an√°lisis SQL\n",
    "        final_export_query = \"\"\"\n",
    "        SELECT \n",
    "            Date,\n",
    "            ROUND(Close, 2) as Close,\n",
    "            ROUND(Volume, 0) as Volume,\n",
    "            ROUND(Daily_Return * 100, 3) as Daily_Return_Pct,\n",
    "            Year,\n",
    "            Month,\n",
    "            DayOfWeek,\n",
    "            Quarter\n",
    "        FROM tesla_stock\n",
    "        ORDER BY Date\n",
    "        \"\"\"\n",
    "        \n",
    "        export_df = pd.read_sql_query(final_export_query, conn)\n",
    "        export_df.to_csv('results/tesla_sql_analysis_results.csv', index=False)\n",
    "        \n",
    "        print(\"üíæ Resultados exportados a 'results/tesla_sql_analysis_results.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al exportar resultados: {e}\")\n",
    "    \n",
    "    # Cerrar conexi√≥n\n",
    "    conn.close()\n",
    "    print(\"‚úÖ Conexi√≥n a la base de datos cerrada\")\n",
    "    print(\"üîí Recursos limpiados exitosamente\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No hay conexi√≥n activa para cerrar\")\n",
    "\n",
    "print(\"\\nüéä ¬°AN√ÅLISIS SQL DE TESLA COMPLETADO!\")\n",
    "print(\"üìà Datos analizados comprehensivamente con consultas SQL avanzadas\")\n",
    "print(\"üöÄ ¬°Listo para la siguiente fase del proyecto!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Resultados exportados a 'results/tesla_sql_analysis_results.csv'\n",
      "‚úÖ Conexi√≥n a la base de datos cerrada\n",
      "üîí Recursos limpiados exitosamente\n",
      "\n",
      "üéä ¬°AN√ÅLISIS SQL DE TESLA COMPLETADO!\n",
      "üìà Datos analizados comprehensivamente con consultas SQL avanzadas\n",
      "üöÄ ¬°Listo para la siguiente fase del proyecto!\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
